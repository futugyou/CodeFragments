
using System.ComponentModel;
using System.Text.Json.Schema;
using System.Text.Json.Serialization;

namespace AspnetcoreEx.KernelService.Tools;


public static class Prompts
{
    public static readonly JsonSerializerOptions DefaultJsonOptions = JsonSerializerOptions.Default;

    public static string BuildSystemPrompt(string instruction = "", string example = "", string pydanticSchema = "")
    {
        string delimiter = "\n\n---\n\n";
        string schema = $"Your answer should be in JSON and strictly follow this schema, filling in the fields in the order they are given:\n```\n{pydanticSchema}\n```";

        if (!string.IsNullOrWhiteSpace(example))
        {
            example = delimiter + example.Trim();
        }

        if (!string.IsNullOrWhiteSpace(pydanticSchema))
        {
            schema = delimiter + schema.Trim();
        }
        else
        {
            schema = "";
        }

        return instruction.Trim() + schema + example;
    }

    public static class RephrasedQuestionsPrompt
    {
        private const string instruction = """
You are a question rephrasing system.
Your task is to break down a comparative question into individual questions for each company mentioned.
Each output question must be self-contained, maintain the same intent and metric as the original question, be specific to the respective company, and use consistent phrasing.
""";

        private const string pydanticSchema = @"
class RephrasedQuestion(BaseModel):
    """"Individual question for a company""""
    company_name: str = Field(description=""Company name, exactly as provided in quotes in the original question"")
    question: str = Field(description=""Rephrased question specific to this company"")

class RephrasedQuestions(BaseModel):
    """"List of rephrased questions""""
    questions: List['RephrasedQuestionsPrompt.RephrasedQuestion'] = Field(description=""List of rephrased questions for each company"")
";

        private const string example = @"
Example:
Input:
Original comparative question: 'Which company had higher revenue in 2022, ""Apple"" or ""Microsoft""?'
Companies mentioned: ""Apple"", ""Microsoft""

Output:
{
    ""questions"": [
        {
            ""company_name"": ""Apple"",
            ""question"": ""What was Apple's revenue in 2022?""
        },
        {
            ""company_name"": ""Microsoft"", 
            ""question"": ""What was Microsoft's revenue in 2022?""
        }
    ]
}
";

        public const string UserPrompt = "Original comparative question: '{0}'\n\nCompanies mentioned: {1}";
        public static readonly string SystemPrompt = BuildSystemPrompt(instruction, example);
        public static readonly string SystemPromptWithSchema = BuildSystemPrompt(instruction, example, pydanticSchema);
    }

    public static class AnswerWithRAGContextSharedPrompt
    {
        public const string Instruction = """
You are a RAG (Retrieval-Augmented Generation) answering system.
Your task is to answer the given question based only on information from the company's annual report, which is uploaded in the format of relevant pages extracted using RAG.

Before giving a final answer, carefully think out loud and step by step. Pay special attention to the wording of the question.
- Keep in mind that the content containing the answer may be worded differently than the question.
- The question was autogenerated from a template, so it may be meaningless or not applicable to the given company.
""";


        public const string UserPrompt = """
Here is the context:
\"\"\"
{0}
\"\"\"

---

Here is the question:
"{1}"
""";
    }

    public static class AnswerWithRAGContextNamePrompt
    {
        private const string instruction = AnswerWithRAGContextSharedPrompt.Instruction;

        private const string pydanticSchema = @"
class AnswerSchema(BaseModel):
    step_by_step_analysis: str = Field(description=""Detailed step-by-step analysis of the answer with at least 5 steps and at least 150 words. Pay special attention to the wording of the question to avoid being tricked. Sometimes it seems that there is an answer in the context, but this is might be not the requested value, but only a similar one."")

    reasoning_summary: str = Field(description=""Concise summary of the step-by-step reasoning process. Around 50 words."")

    relevant_pages: List[int] = Field(description=\""""
List of page numbers containing information directly used to answer the question. Include only:
- Pages with direct answers or explicit statements
- Pages with key information that strongly supports the answer
Do not include pages with only tangentially related information or weak connections to the answer.
At least one page should be included in the list.
\"""")

    final_answer: Union[str, Literal[""N/A""]] = Field(description=\""""
If it is a company name, should be extracted exactly as it appears in question.
If it is a person name, it should be their full name.
If it is a product name, it should be extracted exactly as it appears in the context.
Without any extra information, words or comments.
- Return 'N/A' if information is not available in the context
\"""")
";

        private const string example = """
Example:
Question: 
"Who was the CEO of 'Southwest Airlines Co.'?" 

Answer: 
```
{
  "step_by_step_analysis": "1. The question asks for the CEO of 'Southwest Airlines Co.'. The CEO is typically the highest-ranking executive responsible for the overall management of the company, sometimes referred to as the President or Managing Director.\n2. My source of information is a document that appears to be 'Southwest Airlines Co.''s annual report. This document will be used to identify the individual holding the CEO position.\n3. Within the provided document, there is a section that identifies Robert E. Jordan as the President & Chief Executive Officer of 'Southwest Airlines Co.'. The document confirms his role since February 2022.\n4. Therefore, based on the information found in the document, the CEO of 'Southwest Airlines Co.' is Robert E. Jordan.",
  "reasoning_summary": "'Southwest Airlines Co.''s annual report explicitly names Robert E. Jordan as President & Chief Executive Officer since February 2021. This directly answers the question.",
  "relevant_pages": [58],
  "final_answer": "Robert E. Jordan"
}
```
""";

        public const string UserPrompt = AnswerWithRAGContextSharedPrompt.UserPrompt;
        public static readonly string SystemPrompt = BuildSystemPrompt(instruction, example);
        public static readonly string SystemPromptWithSchema = BuildSystemPrompt(instruction, example, DefaultJsonOptions.GetJsonSchemaAsNode(typeof(NameAnswerSchema)).ToString());
    }

    public static class AnswerWithRAGContextNumberPrompt
    {
        private const string instruction = AnswerWithRAGContextSharedPrompt.Instruction;
        public const string UserPrompt = AnswerWithRAGContextSharedPrompt.UserPrompt;
        private const string example = """
Example 1:
Question:
"What was the total assets of 'Waste Connections Inc.' in the fiscal year 2022?"

Answer:
```
{
  "step_by_step_analysis": "1. **Metric Definition:** The question asks for 'total assets' for 'Waste Connections Inc.' in fiscal year 2022.  'Total assets' represents the sum of all resources owned or controlled by the company, expected to provide future economic benefits.\n2. **Context Examination:** The context includes 'Consolidated Balance Sheets' (page 78), a standard financial statement that reports a company's assets, liabilities, and equity.\n3. **Metric Matching:** On page 78, under 'December 31, 2022', a line item labeled 'Total assets' exists.  This directly matches the concept requested in the question.\n4. **Value Extraction and Adjustment:** The value for 'Total assets' is '$18,500,342'. The context indicates this is in thousands of dollars.  Therefore, the full value is 18,500,342,000.\n5. **Confirmation**: No calculation beyond unit adjustment was needed. The reported metric directly matches the question.",
  "reasoning_summary": "The 'Total assets' value for fiscal year 2022 was directly found on the 'Consolidated Balance Sheets' (page 78). The reported value was in thousands, requiring multiplication by 1000 for the final answer.",
  "relevant_pages": [78],
  "final_answer": 18500342000
}
```


Example 2:
Question:
"For Ritter Pharmaceuticals, Inc., what was the value of Research and development equipment, at cost at the end of the period listed in annual report?"

Answer:
```
{
  "step_by_step_analysis": "1. The question asks for 'Research and development equipment, at cost' for Ritter Pharmaceuticals, Inc. This indicates a specific value from the balance sheet, representing the *original purchase price* of equipment specifically used for R&D, *without* any accumulated depreciation.\n2. The context (page 35) shows 'Property and equipment, net' at $12,500.  This is a *net* value (after depreciation), and it's a *broader* category, encompassing all property and equipment, not just R&D equipment.\n3. The context (page 37) also mentions 'Accumulated Depreciation' of $110,000 for 'Machinery and Equipment'. This represents the total *depreciation*, not the original cost, and, importantly, it doesn't specify that this equipment is *exclusively* for R&D.\n4. Neither of these metrics *exactly* matches the requested metric. 'Property and equipment, net' is too broad and represents the depreciated value. 'Accumulated Depreciation' only shows depreciation, not cost, and lacks R&D specificity.\n5. Since the context doesn't provide the *original cost* of *only* R&D equipment, and we cannot make assumptions, perform calculations, or combine information, the answer is 'N/A'.",
  "reasoning_summary": "The context lacks a specific line item for 'Research and development equipment, at cost.' 'Property and equipment, net' is depreciated and too broad, while 'Accumulated Depreciation' only represents depreciation, not original cost, and is not R&D-specific. Strict matching requires 'N/A'.",
  "relevant_pages": [ 35, 37 ],
  "final_answer": "N/A"
}
```
""";
        public static readonly string SystemPrompt = BuildSystemPrompt(instruction, example);
        public static readonly string SystemPromptWithSchema = BuildSystemPrompt(instruction, example, DefaultJsonOptions.GetJsonSchemaAsNode(typeof(NumberAnswerSchema)).ToString());
    }

    public static class AnswerWithRAGContextBooleanPrompt
    {
        private const string instruction = AnswerWithRAGContextSharedPrompt.Instruction;
        public const string UserPrompt = AnswerWithRAGContextSharedPrompt.UserPrompt;
        private const string example = """
Question:
"Did W. P. Carey Inc. announce any changes to its dividend policy in the annual report?"

Answer:
```
{
  "step_by_step_analysis": "1. The question asks whether W. P. Carey Inc. announced changes to its dividend policy.\n2. The phrase 'changes to its dividend policy' requires careful interpretation. It means any adjustment to the framework, rules, or stated intentions that dictate how the company determines and distributes dividends.\n3. The context (page 12, 18) states that the company increased its annualized dividend to $4.27 per share in the fourth quarter of 2023, compared to $4.22 per share in the same period of 2022. Page 45 mentions further details about dividend.\n4. Consistent, incremental increases throughout the year, with explicit mentions of maintaining a 'steady and growing' dividend, indicates no changes to *policy*, though the *amount* increased as planned within the existing policy.",
  "reasoning_summary": "The context highlights consistent, small increases to the dividend throughout the year, consistent with a stated policy of providing a 'steady and growing' dividend. While the dividend *amount* changed, the *policy* governing those increases remained consistent. The question asks about *policy* changes, not amount changes.",
  "relevant_pages": [12, 18, 45],
  "final_answer": False
}
```
""";
        public static readonly string SystemPrompt = BuildSystemPrompt(instruction, example);
        public static readonly string SystemPromptWithSchema = BuildSystemPrompt(instruction, example, DefaultJsonOptions.GetJsonSchemaAsNode(typeof(BooleanAnswerSchema)).ToString());

    }

    public static class AnswerWithRAGContextNamesPrompt
    {
        private const string instruction = AnswerWithRAGContextSharedPrompt.Instruction;
        public const string UserPrompt = AnswerWithRAGContextSharedPrompt.UserPrompt;
        private const string example = """
Example:
Question:
"What are the names of all new executives that took on new leadership positions in company?"

Answer:
```
{
    "step_by_step_analysis": "1. The question asks for the names of all new executives who took on new leadership positions in the company.\n2. Exhibit 10.9 and 10.10, as listed in the Exhibit Index on page 89, mentions new Executive Agreements with Carly Kennedy and Brian Appelgate.\n3. Exhibit 10.9, Employment Agreement with Carly Kennedy, states her start date as April 4, 2022, and her position as Executive Vice President and General Counsel.\n4. Exhibit 10.10, Offer Letter with Brian Appelgate shows that his new role within the company is Interim Chief Operations Officer, and he was accepting the offer on November 8, 2022.\n5. Based on the documents, Carly Kennedy and Brian Appelgate are named as the new executives.",
    "reasoning_summary": "Exhibits 10.9 and 10.10 of the annual report, described as Employment Agreement and Offer Letter, explicitly name Carly Kennedy and Brian Appelgate taking on new leadership roles within the company in 2022.",
    "relevant_pages": [
        89
    ],
    "final_answer": [
        "Carly Kennedy",
        "Brian Appelgate"
    ]
}
```
""";
        public static readonly string SystemPrompt = BuildSystemPrompt(instruction, example);
        public static readonly string SystemPromptWithSchema = BuildSystemPrompt(instruction, example, DefaultJsonOptions.GetJsonSchemaAsNode(typeof(NamesAnswerSchema)).ToString());

    }

    public static class ComparativeAnswerPrompt
    {
        private const string instruction =  """
You are a question answering system.
Your task is to analyze individual company answers and provide a comparative response that answers the original question.
Base your analysis only on the provided individual answers - do not make assumptions or include external knowledge.
Before giving a final answer, carefully think out loud and step by step.

Important rules for comparison:
- When the question asks to choose one of the companies (e.g., when comparing metrics), return the company name exactly as it appears in the original question
- If a company's metric is in a different currency than what is asked in the question, exclude that company from comparison
- If all companies are excluded (due to currency mismatch or other reasons), return 'N/A' as the final answer
- If all companies except one are excluded, return the name of the remaining company (even though there is no actual comparison possible)
""";
        public const string UserPrompt = """
Here are the individual company answers:
\"\"\"
{0}
\"\"\"

---

Here is the original comparative question:
"{1}"
""";
        private const string example = """
Example:
Question:
"Which of the companies had the lowest total assets in USD at the end of the period listed in the annual report: "CrossFirst Bank", "Sleep Country Canada Holdings Inc.", "Holley Inc.", "PowerFleet, Inc.", "Petra Diamonds"? If data for the company is not available, exclude it from the comparison."

Answer:
```
{
  "step_by_step_analysis": "1. The question asks for the company with the lowest total assets in USD.\n2. Gather the total assets in USD for each company from the individual answers: CrossFirst Bank: $6,601,086,000; Holley Inc.: $1,249,642,000; PowerFleet, Inc.: $217,435,000; Petra Diamonds: $1,078,600,000.\n3. Sleep Country Canada Holdings Inc. is excluded because its assets are not reported in USD.\n4. Compare the total assets: PowerFleet, Inc. ($217,435,000) < Petra Diamonds ($1,078,600,000) < Holley Inc. ($1,249,642,000)  < CrossFirst Bank ($6,601,086,000).\n5. Therefore, PowerFleet, Inc. has the lowest total assets in USD.",
  "reasoning_summary": "The individual answers provided the total assets in USD for each company except Sleep Country Canada Holdings Inc. (excluded due to currency mismatch). Direct comparison shows PowerFleet, Inc. has the lowest total assets.",
  "relevant_pages": [],
  "final_answer": "PowerFleet, Inc."
}
```
""";
        public static readonly string SystemPrompt = BuildSystemPrompt(instruction, example);
        public static readonly string SystemPromptWithSchema = BuildSystemPrompt(instruction, example, DefaultJsonOptions.GetJsonSchemaAsNode(typeof(ComparativeAnswerSchema)).ToString());

    }
}

/// <summary>
/// Individual question for a company
/// </summary>
public class RephrasedQuestion
{
    [JsonPropertyName("company_name")]
    [Description("Company name, exactly as provided in quotes in the original question")]
    public string CompanyName { get; set; }

    [JsonPropertyName("question")]
    [Description("Rephrased question specific to this company")]
    public string Question { get; set; }
}

/// <summary>
/// List of rephrased questions
/// </summary>
public class RephrasedQuestions
{
    [JsonPropertyName("questions")]
    [Description("List of rephrased questions for each company")]
    public List<RephrasedQuestion> Questions { get; set; }
}

/// <summary>
/// Rank retrieved text block relevance to a query.
/// </summary>
public class RetrievalRankingSingleBlock
{
    [JsonPropertyName("reasoning")]
    [Description("Analysis of the block, identifying key information and how it relates to the query")]
    public string Reasoning { get; set; }

    [JsonPropertyName("relevance_score")]
    [Description("Relevance score from 0 to 1, where 0 is Completely Irrelevant and 1 is Perfectly Relevant")]
    public double RelevanceScore { get; set; }
}

/// <summary>
/// Rank retrieved multiple text blocks relevance to a query.
/// </summary>
public class RetrievalRankingMultipleBlocks
{
    [JsonPropertyName("block_rankings")]
    [Description("A list of text blocks and their associated relevance scores.")]
    public List<RetrievalRankingSingleBlock> BlockRankings { get; set; }
}

public class NameAnswerSchema
{
    [JsonPropertyName("step_by_step_analysis")]
    [Description("Detailed step-by-step analysis of the answer with at least 5 steps and at least 150 words. Pay special attention to the wording of the question to avoid being tricked. Sometimes it seems that there is an answer in the context, but this is might be not the requested value, but only a similar one.")]
    public string StepByStepAnalysis { get; set; }

    [JsonPropertyName("reasoning_summary")]
    [Description("Concise summary of the step-by-step reasoning process. Around 50 words.")]
    public string ReasoningSummary { get; set; }

    [JsonPropertyName("relevant_pages")]
    [Description("""
List of page numbers containing information directly used to answer the question. Include only:
- Pages with direct answers or explicit statements
- Pages with key information that strongly supports the answer
Do not include pages with only tangentially related information or weak connections to the answer.
At least one page should be included in the list.
""")]
    public List<int> RelevantPages { get; set; }

    [JsonPropertyName("final_answer")]
    [Description("""
If it is a company name, should be extracted exactly as it appears in question.
If it is a person name, it should be their full name.
If it is a product name, it should be extracted exactly as it appears in the context.
Without any extra information, words or comments.
- Return 'N/A' if information is not available in the context
""")]
    public string FinalAnswer { get; set; }
}

public class NumberAnswerSchema
{
    [JsonPropertyName("step_by_step_analysis")]
    [Description("""
Detailed step-by-step analysis of the answer with at least 5 steps and at least 150 words.
**Strict Metric Matching Required:**    

1. Determine the precise concept the question's metric represents. What is it actually measuring?
2. Examine potential metrics in the context. Don't just compare names; consider what the context metric measures.
3. Accept ONLY if: The context metric's meaning *exactly* matches the target metric. Synonyms are acceptable; conceptual differences are NOT.
4. Reject (and use 'N/A') if:
    - The context metric covers more or less than the question's metric.
    - The context metric is a related concept but not the *exact* equivalent (e.g., a proxy or a broader category).
    - Answering requires calculation, derivation, or inference.
    - Aggregation Mismatch: The question needs a single value but the context offers only an aggregated total
5. No Guesswork: If any doubt exists about the metric's equivalence, default to `N/A`."
""")]
    public string StepByStepAnalysis { get; set; }

    [JsonPropertyName("reasoning_summary")]
    [Description("Concise summary of the step-by-step reasoning process. Around 50 words.")]
    public string ReasoningSummary { get; set; }

    [JsonPropertyName("relevant_pages")]
    [Description("""
List of page numbers containing information directly used to answer the question. Include only:
- Pages with direct answers or explicit statements
- Pages with key information that strongly supports the answer
Do not include pages with only tangentially related information or weak connections to the answer.
At least one page should be included in the list.
""")]
    public List<int> RelevantPages { get; set; }

    [JsonPropertyName("final_answer")]
    [Description("""
An exact metric number is expected as the answer.
- Example for percentages:
    Value from context: 58,3%
    Final answer: 58.3

Pay special attention to any mentions in the context about whether metrics are reported in units, thousands, or millions to adjust number in final answer with no changes, three zeroes or six zeroes accordingly.
Pay attention if value wrapped in parentheses, it means that value is negative.

- Example for negative values:
    Value from context: (2,124,837) CHF
    Final answer: -2124837

- Example for numbers in thousands:
    Value from context: 4970,5 (in thousands $)
    Final answer: 4970500

- Return 'N/A' if metric provided is in a different currency than mentioned in the question
    Example of value from context: 780000 USD, but question mentions EUR
    Final answer: 'N/A'

- Return 'N/A' if metric is not directly stated in context EVEN IF it could be calculated from other metrics in the context
    Example: Requested metric: Dividend per Share; Only available metrics from context: Total Dividends Paid ($5,000,000), and Number of Outstanding Shares (1,000,000); Calculated DPS = Total Dividends / Outstanding Shares.
    Final answer: 'N/A'

- Return 'N/A' if information is not available in the context
""")]
    public string FinalAnswer { get; set; }
}

public class BooleanAnswerSchema
{
    [JsonPropertyName("step_by_step_analysis")]
    [Description("""
Detailed step-by-step analysis of the answer with at least 5 steps and at least 150 words. Pay special attention to the wording of the question to avoid being tricked. Sometimes it seems that there is an answer in the context, but this is might be not the requested value, but only a similar one.
""")]
    public string StepByStepAnalysis { get; set; }

    [JsonPropertyName("reasoning_summary")]
    [Description("Concise summary of the step-by-step reasoning process. Around 50 words.")]
    public string ReasoningSummary { get; set; }

    [JsonPropertyName("relevant_pages")]
    [Description("""
List of page numbers containing information directly used to answer the question. Include only:
- Pages with direct answers or explicit statements
- Pages with key information that strongly supports the answer
Do not include pages with only tangentially related information or weak connections to the answer.
At least one page should be included in the list.
""")]
    public List<int> RelevantPages { get; set; }

    [JsonPropertyName("final_answer")]
    [Description("""
A boolean value (True or False) extracted from the context that precisely answers the question.
If question ask about did something happen, and in context there is information about it, return False.
""")]
    public bool FinalAnswer { get; set; }
}

public class NamesAnswerSchema
{
    [JsonPropertyName("step_by_step_analysis")]
    [Description("Detailed step-by-step analysis of the answer with at least 5 steps and at least 150 words. Pay special attention to the wording of the question to avoid being tricked. Sometimes it seems that there is an answer in the context, but this is might be not the requested value, but only a similar one.")]
    public string StepByStepAnalysis { get; set; }

    [JsonPropertyName("reasoning_summary")]
    [Description("Concise summary of the step-by-step reasoning process. Around 50 words.")]
    public string ReasoningSummary { get; set; }

    [JsonPropertyName("relevant_pages")]
    [Description("""
List of page numbers containing information directly used to answer the question. Include only:
- Pages with direct answers or explicit statements
- Pages with key information that strongly supports the answer
Do not include pages with only tangentially related information or weak connections to the answer.
At least one page should be included in the list.
""")]
    public List<int> RelevantPages { get; set; }

    [JsonPropertyName("final_answer")]
    [Description("""
Example:
Question:
"What are the names of all new executives that took on new leadership positions in company?"

Answer:
```
{
    "step_by_step_analysis": "1. The question asks for the names of all new executives who took on new leadership positions in the company.\n2. Exhibit 10.9 and 10.10, as listed in the Exhibit Index on page 89, mentions new Executive Agreements with Carly Kennedy and Brian Appelgate.\n3. Exhibit 10.9, Employment Agreement with Carly Kennedy, states her start date as April 4, 2022, and her position as Executive Vice President and General Counsel.\n4. Exhibit 10.10, Offer Letter with Brian Appelgate shows that his new role within the company is Interim Chief Operations Officer, and he was accepting the offer on November 8, 2022.\n5. Based on the documents, Carly Kennedy and Brian Appelgate are named as the new executives.",
    "reasoning_summary": "Exhibits 10.9 and 10.10 of the annual report, described as Employment Agreement and Offer Letter, explicitly name Carly Kennedy and Brian Appelgate taking on new leadership roles within the company in 2022.",
    "relevant_pages": [
        89
    ],
    "final_answer": [
        "Carly Kennedy",
        "Brian Appelgate"
    ]
}
```
""")]
    public List<string> FinalAnswer { get; set; }
}

public class ComparativeAnswerSchema
{
    [JsonPropertyName("step_by_step_analysis")]
    [Description("Detailed step-by-step analysis of the answer with at least 5 steps and at least 150 words.")]
    public string StepByStepAnalysis { get; set; }

    [JsonPropertyName("reasoning_summary")]
    [Description("Concise summary of the step-by-step reasoning process. Around 50 words.")]
    public string ReasoningSummary { get; set; }

    [JsonPropertyName("relevant_pages")]
    [Description("Just leave empty")]
    public List<int> RelevantPages { get; set; }

    [JsonPropertyName("final_answer")]
    [Description("""
Company name should be extracted exactly as it appears in question.
Answer should be either a single company name or 'N/A' if no company is applicable.
""")]
    public string FinalAnswer { get; set; }
}
